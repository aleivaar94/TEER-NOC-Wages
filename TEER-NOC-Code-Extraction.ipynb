{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3936baba-4402-4f54-ac6d-286520a33ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ale\\AppData\\Local\\Temp/ipykernel_66052/2014370234.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver # Initialize web browser\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b967b41b-cfec-48f2-ad14-bebc7f5b985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ircc_2021(url, filename):\n",
    "    teer_list = []\n",
    "    noc_list = []\n",
    "    title_list = []\n",
    "\n",
    "    driver.get(url)\n",
    "    for i in range(60):\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        table = soup.find('table', class_='wb-tables table wb-init wb-tables-inited dataTable no-footer')\n",
    "        teer_categories = table.find_all('td', class_='sorting_1')\n",
    "        noc_title = table.find_all('td', class_='')\n",
    "\n",
    "        for teer in teer_categories:\n",
    "            teer_list.append(teer.text)\n",
    "\n",
    "        for count, value in enumerate(noc_title):\n",
    "            if count%2 == 0: # odd number\n",
    "                noc_list.append(value.text)\n",
    "            else:\n",
    "                title_list.append(value.text)\n",
    "        print(f'Extracting page {i+1}')\n",
    "\n",
    "        try:\n",
    "            next_button = driver.find_element('xpath', '//*[@id=\"wb-auto-5_next\"]')\n",
    "            next_button.send_keys('\\n')\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            break\n",
    "    print('Done')\n",
    "\n",
    "    df = pd.DataFrame({'teer_category': teer_list,\n",
    "                       'noc_code': noc_list,\n",
    "                       'class_title': title_list})\n",
    "    return df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e4430-d4f9-4fab-8d27-4ce41ab25704",
   "metadata": {},
   "source": [
    "## 2021 NOC Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1847d107-1224-4c74-82a1-ae1e8fce50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1\n",
      "Extracting page 2\n",
      "Extracting page 3\n",
      "Extracting page 4\n",
      "Extracting page 5\n",
      "Extracting page 6\n",
      "Extracting page 7\n",
      "Extracting page 8\n",
      "Extracting page 9\n",
      "Extracting page 10\n",
      "Extracting page 11\n",
      "Extracting page 12\n",
      "Extracting page 13\n",
      "Extracting page 14\n",
      "Extracting page 15\n",
      "Extracting page 16\n",
      "Extracting page 17\n",
      "Extracting page 18\n",
      "Extracting page 19\n",
      "Extracting page 20\n",
      "Extracting page 21\n",
      "Extracting page 22\n",
      "Extracting page 23\n",
      "Extracting page 24\n",
      "Extracting page 25\n",
      "Extracting page 26\n",
      "Extracting page 27\n",
      "Extracting page 28\n",
      "Extracting page 29\n",
      "Extracting page 30\n",
      "Extracting page 31\n",
      "Extracting page 32\n",
      "Extracting page 33\n",
      "Extracting page 34\n",
      "Extracting page 35\n",
      "Extracting page 36\n",
      "Extracting page 37\n",
      "Extracting page 38\n",
      "Extracting page 39\n",
      "Extracting page 40\n",
      "Extracting page 41\n",
      "Extracting page 42\n",
      "Extracting page 43\n",
      "Extracting page 44\n",
      "Extracting page 45\n",
      "Extracting page 46\n",
      "Extracting page 47\n",
      "Extracting page 48\n",
      "Extracting page 49\n",
      "Extracting page 50\n",
      "Extracting page 51\n",
      "Extracting page 52\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "noc_2021_url = 'https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/eligibility/find-national-occupation-code.html#wb-auto-5' \n",
    "extract_ircc_2021(noc_2021_url, 'noc_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07160a9-480d-4a97-809b-ee767dd72e44",
   "metadata": {},
   "source": [
    "## 2016 NOC Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f30c670a-79a8-4f59-9f56-2e8637899cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ircc_2016(url, filename):\n",
    "    noc_list = []\n",
    "    skill_list = []\n",
    "    title_list = []\n",
    "\n",
    "    driver.get(url)\n",
    "    for i in range(60):\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        table = soup.find('table', class_='wb-tables table wb-init wb-tables-inited dataTable no-footer')\n",
    "        noc_categories = table.find_all('td', class_='sorting_1')\n",
    "        noc_title = table.find_all('td', class_='')\n",
    "\n",
    "        for noc in noc_categories:\n",
    "            noc_list.append(noc.text)\n",
    "\n",
    "        for count, value in enumerate(noc_title):\n",
    "            if count%2 == 0: # odd number\n",
    "                title_list.append(value.text)\n",
    "            else:\n",
    "                skill_list.append(value.text)\n",
    "        print(f'Extracting page {i+1}')\n",
    "\n",
    "        try:\n",
    "            next_button = driver.find_element('xpath', '//*[@id=\"noc_next\"]')\n",
    "            next_button.send_keys('\\n')\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            break\n",
    "    print('Done')\n",
    "\n",
    "    df = pd.DataFrame({'noc_code': noc_list,\n",
    "                       'skill_level': skill_list,\n",
    "                       'class_title': title_list})\n",
    "    return df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fdc703-2796-4063-b11f-f68b355a46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "table = soup.find('table', class_='wb-tables table wb-init wb-tables-inited dataTable no-footer')\n",
    "noc_categories = table.find_all('td', class_='sorting_1')\n",
    "noc_title = table.find_all('td', class_='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27724489-c585-42ae-af6e-2f5f4b78771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0011'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noc_categories[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f24fda97-0565-4f7c-a189-4444038e84b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1\n",
      "Extracting page 2\n",
      "Extracting page 3\n",
      "Extracting page 4\n",
      "Extracting page 5\n",
      "Extracting page 6\n",
      "Extracting page 7\n",
      "Extracting page 8\n",
      "Extracting page 9\n",
      "Extracting page 10\n",
      "Extracting page 11\n",
      "Extracting page 12\n",
      "Extracting page 13\n",
      "Extracting page 14\n",
      "Extracting page 15\n",
      "Extracting page 16\n",
      "Extracting page 17\n",
      "Extracting page 18\n",
      "Extracting page 19\n",
      "Extracting page 20\n",
      "Extracting page 21\n",
      "Extracting page 22\n",
      "Extracting page 23\n",
      "Extracting page 24\n",
      "Extracting page 25\n",
      "Extracting page 26\n",
      "Extracting page 27\n",
      "Extracting page 28\n",
      "Extracting page 29\n",
      "Extracting page 30\n",
      "Extracting page 31\n",
      "Extracting page 32\n",
      "Extracting page 33\n",
      "Extracting page 34\n",
      "Extracting page 35\n",
      "Extracting page 36\n",
      "Extracting page 37\n",
      "Extracting page 38\n",
      "Extracting page 39\n",
      "Extracting page 40\n",
      "Extracting page 41\n",
      "Extracting page 42\n",
      "Extracting page 43\n",
      "Extracting page 44\n",
      "Extracting page 45\n",
      "Extracting page 46\n",
      "Extracting page 47\n",
      "Extracting page 48\n",
      "Extracting page 49\n",
      "Extracting page 50\n",
      "Extracting page 51\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "noc_2016_url = 'https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/express-entry/eligibility/find-national-occupation-code-2016.html'\n",
    "extract_ircc_2016(noc_2016_url, 'noc_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fec1e8-4034-4390-8e5d-238c94c06951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
